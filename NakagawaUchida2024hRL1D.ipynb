{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FreeIntake(Control)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy import stats\n",
    "\n",
    "mpl.use(\"PS\")\n",
    "mpl.rcParams['ps.useafm'] = False  # TrueにするとCMYKになることがある\n",
    "mpl.rcParams['ps.fonttype'] = 42  # フォントの埋め込みを防ぐ\n",
    "mpl.rcParams['image.cmap'] = 'twilight'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_episode, N_timestep = 1, 200  # Number of episodes, number of timesteps\n",
    "\n",
    "class Train:\n",
    "    def __init__(self):\n",
    "        self.N = N_timestep\n",
    "        self.a, self.P = np.zeros(self.N), np.zeros(self.N)  # 0 or 1, p(intake)\n",
    "        self.D, self.D_est = np.zeros(self.N + 1), np.zeros(self.N + 1)  # d(Ht), d(Ht+1)\n",
    "        self.H, self.H_ast = np.zeros(self.N + 1), 200  # internal state, setpoint\n",
    "        self.H[0] = 100  # depleted internal state\n",
    "\n",
    "        self.K, self.K_hat = np.zeros(self.N), np.zeros((2, self.N + 1))  # K, K hat\n",
    "        self.Q, self.R = np.zeros((2, self.N + 1)), np.zeros(self.N)  # Q value, reward\n",
    "        \n",
    "        self.alpha_Q, self.beta = 0.3, 0.6  # learning rate of Q, inverse temperature\n",
    "        self.gamma, self.tau = 0.9, 200  # discount rate, attenuation rate of the internal state\n",
    "        self.alpha_K_hat = 0.3  # learning rate of K_hat\n",
    "        self.mouth = 2  # volume of an intake\n",
    "        \n",
    "        self.m, self.n = 3, 4\n",
    "        self.K_hat[1][0] = self.mouth\n",
    "        \n",
    "\n",
    "    def softmax(self, t):\n",
    "        self.t = t\n",
    "        Q_larger = max(self.Q[:, self.t])\n",
    "        sigma = np.sum(np.exp((self.Q[:, self.t] - Q_larger) * self.beta))\n",
    "        vals = []\n",
    "        for i in range(2):\n",
    "            softmax = np.exp((self.Q[i, self.t] - Q_larger) * self.beta) / sigma\n",
    "            vals.append(softmax)\n",
    "            if i == 1:\n",
    "                self.P[self.t] = softmax\n",
    "            \n",
    "        dice = stats.uniform.rvs()\n",
    "        if dice <= vals[0]:\n",
    "            self.a[self.t] = 0\n",
    "        elif vals[0] < dice:\n",
    "            self.a[self.t] = 1\n",
    "\n",
    "            \n",
    "    def get_intake(self, t):\n",
    "        self.t = t\n",
    "        if self.a[self.t] == 1:\n",
    "            self.K[self.t] = self.mouth\n",
    "            \n",
    "\n",
    "    def get_drive(self, t):\n",
    "        self.t = t\n",
    "        self.D[self.t] =  (abs(self.H_ast - self.H[self.t]) ** self.n) ** (1 / self.m)\n",
    "        if self.a[self.t] == 1:  # intake\n",
    "            self.D_est[self.t] = (abs(self.H_ast - (1 - 1 / self.tau) * self.H[self.t] - self.K[self.t]) ** self.n) ** (1 / self.m)\n",
    "        else:\n",
    "            self.D_est[self.t] = (abs(self.H_ast - (1 - 1 / self.tau) * self.H[self.t]) ** self.n) ** (1 / self.m)\n",
    "\n",
    "\n",
    "    def update_K_hat(self, t):\n",
    "        self.t = t\n",
    "        if self.a[self.t] == 0:\n",
    "            self.K[self.t] = 0\n",
    "            self.K_hat[0][self.t + 1] = self.K_hat[0][self.t]\n",
    "            self.K_hat[1][self.t + 1] = self.K_hat[1][self.t]\n",
    "            \n",
    "        else:\n",
    "            self.K[self.t] = self.mouth\n",
    "            self.K_hat[0][self.t + 1] = self.K_hat[0][self.t]\n",
    "            self.K_hat[1][self.t + 1] = (1 - self.alpha_K_hat) * self.K_hat[1][self.t] + self.alpha_K_hat * self.mouth\n",
    "\n",
    "\n",
    "    def get_reward(self, t):\n",
    "        self.t = t\n",
    "        if self.H[self.t] < 50:\n",
    "            self.R[self.t] = self.D[self.t] - self.D_est[self.t]\n",
    "        else:\n",
    "            self.R[self.t] = self.D[self.t] - self.D_est[self.t]\n",
    "    \n",
    "\n",
    "    def update_H(self, t):\n",
    "        self.t = t\n",
    "        self.H[self.t+1] = (1 - 1/self.tau) * self.H[self.t] + self.K[self.t]\n",
    "\n",
    "\n",
    "    def update_Q(self, t):\n",
    "        self.t = t\n",
    "        if self.a[self.t] == 0:\n",
    "            self.Q[0][self.t+1] = self.Q[0][self.t] + self.alpha_Q * (self.R[self.t] + self.gamma * max(self.Q[0][self.t], self.Q[1][self.t]) - self.Q[0][self.t])\n",
    "            self.Q[1][self.t+1] = self.Q[1][self.t]\n",
    "            \n",
    "        elif self.a[self.t] == 1:\n",
    "            self.Q[0][self.t + 1] = self.Q[0][self.t]\n",
    "            self.Q[1][self.t + 1] = self.Q[1][self.t] + self.alpha_Q * (self.R[self.t] + self.gamma * max(self.Q[0][self.t], self.Q[1][self.t]) - self.Q[1][self.t])\n",
    "\n",
    "\n",
    "num_l, Nexp_l = list(range(N_timestep + 1)), list(range(N_episode))\n",
    "\n",
    "a_H = np.zeros(N_episode * (N_timestep + 1))\n",
    "a_Q0, a_Q1 = np.zeros(N_episode * (N_timestep + 1)), np.zeros(N_episode * (N_timestep + 1))\n",
    "a_P, a_a = np.zeros(N_episode * (N_timestep + 1)), np.zeros(N_episode * (N_timestep + 1))\n",
    "a_R, a_K_hat = np.zeros(N_episode * (N_timestep + 1)), np.zeros(N_episode * (N_timestep + 1))\n",
    "\n",
    "class_l = []\n",
    "\n",
    "# To make list of Classes\n",
    "for i in range(N_episode):\n",
    "    class_l.append(None)\n",
    "\n",
    "# main\n",
    "for j in range(N_episode):\n",
    "    class_l[j] = Train()    \n",
    "    for i in range(N_timestep):\n",
    "        class_l[j].softmax(i)\n",
    "        class_l[j].get_intake(i)\n",
    "        class_l[j].get_drive(i)\n",
    "        class_l[j].update_K_hat(i)\n",
    "        class_l[j].get_reward(i)\n",
    "        class_l[j].update_Q(i)\n",
    "        class_l[j].update_H(i)\n",
    "        \n",
    "    \n",
    "    a_H[(N_timestep + 1) * j : (N_timestep + 1) * (j + 1)] = class_l[j].H\n",
    "    a_Q0[(N_timestep + 1) * j : (N_timestep + 1) * (j + 1)], a_Q1[(N_timestep + 1) * j : (N_timestep + 1) * (j + 1)] = class_l[j].Q[0], class_l[j].Q[1]\n",
    "    a_P[(N_timestep + 1) * j : (N_timestep + 1) * (j + 1)], a_a[(N_timestep + 1) * j : (N_timestep + 1) * (j + 1)] = np.append(class_l[j].P, np.nan), np.append(class_l[j].a, np.nan)\n",
    "    a_R[(N_timestep + 1) * j : (N_timestep + 1) * (j + 1)], a_K_hat[(N_timestep + 1) * j : (N_timestep + 1) * (j + 1)] = np.append(class_l[j].R, np.nan), class_l[j].K_hat[1]\n",
    "                   \n",
    "df = pd.DataFrame(data=list(range((N_timestep + 1))) * N_episode, columns=['trial'])\n",
    "df['H'], df['Q0'], df['Q1'] = a_H, a_Q0, a_Q1\n",
    "df['P'], df['A'], df['R'] = a_P, a_a, a_R\n",
    "df['K_hat'] = a_K_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    }
   ],
   "source": [
    "plt.rcParams[\"font.size\"] = 18\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "\n",
    "N_figure = 5\n",
    "spec = gridspec.GridSpec(ncols = 1, nrows = N_figure, height_ratios = [2,2,2,2,1])\n",
    "\n",
    "ax_l = []\n",
    "for i in range(N_figure):\n",
    "    ax_l.append(fig.add_subplot(spec[i]))\n",
    "\n",
    "CL, Df, mean = 0.95, N_episode - 1, []  # Confidencial Level for Figures, degree of freedom for Figures\n",
    "\n",
    "for j, h in zip(['H','R','Q0','Q1','P','a'], list(range(N_figure))):\n",
    "    for i in range(N_timestep + 1):\n",
    "        mean.append(sum(df.loc[df['trial'] == i][j]) / N_episode)\n",
    "\n",
    "\n",
    "fs = 16\n",
    "length_l, length_s = N_timestep + 1, N_timestep\n",
    "\n",
    "# Greysカラーマップから中間の灰色を抽出\n",
    "#grey_color = plt.get_cmap('Greys')(0.6)\n",
    "#grey_dashed = plt.get_cmap('Greys')(0.7)\n",
    "\n",
    "ax_i = 0\n",
    "ax_l[ax_i].hlines(200, 0, N_timestep, linestyle=\"dashed\", color='#808080')\n",
    "ax_l[ax_i].plot(df['H'][:length_l], linewidth=2, color=plt.get_cmap('Blues')(0.6))\n",
    "ax_l[ax_i].set_ylabel('Internal\\nstate\\n(H)', fontsize=fs)\n",
    "ax_l[ax_i].set_yticks([100, 200])\n",
    "ax_l[ax_i].set_yticklabels([r'$H_{dep} = 100$', r'$H^{*} = 200$'], fontsize=fs)\n",
    "ax_l[ax_i].tick_params(labelbottom=False)\n",
    "\n",
    "ax_i += 1\n",
    "ax_l[ax_i].hlines(0, 0, N_timestep, linestyle=\"dashed\", color='#808080')\n",
    "ax_l[ax_i].plot(df['R'][:length_s], linewidth=2, color=plt.get_cmap('Greens')(0.6))\n",
    "ax_l[ax_i].set_ylabel('Reward\\n(R)', fontsize=fs)\n",
    "ax_l[ax_i].tick_params(labelbottom=False)\n",
    "\n",
    "ax_i += 1\n",
    "ax_l[ax_i].hlines(0, 0, N_timestep, linestyle=\"dashed\", color='#808080')\n",
    "ax_l[ax_i].plot(df['Q0'][:length_l], linewidth=2, color=plt.get_cmap('GnBu')(0.4), label='Q0')\n",
    "ax_l[ax_i].plot(df['Q1'][:length_l], linewidth=2, color=plt.get_cmap('OrRd')(0.6), label='Q1')\n",
    "ax_l[ax_i].set_ylabel('State\\naction\\nvalue\\n(Q)', fontsize=fs)\n",
    "ax_l[ax_i].legend(loc='best')\n",
    "ax_l[ax_i].tick_params(labelbottom=False)\n",
    "\n",
    "ax_i += 1\n",
    "ax_l[ax_i].hlines(0, 0, N_timestep, linestyle=\"dashed\", color='#808080')\n",
    "ax_l[ax_i].plot(df['P'][:length_s], linewidth=2, color=plt.get_cmap('OrRd')(0.7))\n",
    "ax_l[ax_i].set_ylabel('Probability\\nof\\nintake', fontsize=fs)\n",
    "ax_l[ax_i].tick_params(labelbottom=False)\n",
    "\n",
    "ax_i += 1\n",
    "ax_l[ax_i].hlines(0, 0, N_timestep, linestyle=\"dashed\", color='#808080')\n",
    "ax_l[ax_i].scatter(df['trial'][:length_s], df['A'][:length_s], s=30, color=plt.get_cmap('Greys')(0.3))\n",
    "ax_l[ax_i].set_ylabel('Action\\n(a)', fontsize=fs)\n",
    "ax_l[ax_i].tick_params(labelbottom=False)\n",
    "\n",
    "fig.savefig(\"FigureS3b.eps\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "SaltwaterDopamine",
   "language": "python",
   "name": "saltwaterdopamine"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
